model:
  type: dit  # diffusion transformer
  img_size: 256
  patch_size: 16  # Larger patches for larger images
  in_channels: 3
  hidden_size: 768  # DiT-B configuration
  depth: 12
  num_heads: 12
  mlp_ratio: 4.0
  dropout: 0.0
  timesteps: 1000
  beta_schedule: linear

data:
  dataset: imagenet
  path: "/scratch/groups/swl1/lhy/imagenet"  # Set your ImageNet data path here
  batch_size: 32  # Smaller due to larger images and model
  num_workers: 8
  shuffle: true
  image_size: 256

training:
  epochs: 400
  learning_rate: 1e-4
  weight_decay: 0.0
  grad_clip: 1.0
  
  # Optimizer
  optimizer: adamw
  
  # Learning rate scheduler
  scheduler: cosine
  eta_min: 0
  
  # EMA settings
  use_ema: true
  ema_decay: 0.9999
  ema_inv_gamma: 1.0
  ema_power: 0.6667
  
  # Sampling settings
  sampling_scheduler: ddim
  num_inference_steps: 50
  
  # Checkpointing
  checkpoint_dir: "/oak/stanford/groups/swl1/lhy/checkpoints/generative_models/dit_imagenet_256"
  save_interval: 10
  
  # Logging
  log_interval: 50
  sample_interval: 500
  num_samples: 8

wandb:
  project: "generative-models"
  entity: null
  name: "dit_imagenet_256"
  tags: ["dit", "diffusion-transformer", "imagenet", "256x256"]
  log_model: false

seed: 42