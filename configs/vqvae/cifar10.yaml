model:
  type: vqvae
  image_size: 32          # input image size
  in_channels: 3          # RGB images
  ch: 128                  # base number of feature channels
  ch_mult: [1,2]      # channel multiplier per resolution level
  num_res_blocks: 1       # residual blocks per level
  z_channels: 64   
  num_codebook_vectors: 512
  beta:  0.25
  decay: 0.99

data:
  dataset: cifar10
  path: "/home/groups/swl1/lhy/data/cifar10"  # Set your CIFAR-10 data path here
  batch_size: 256
  num_workers: 4
  shuffle: true

training:
  epochs: 100
  learning_rate: 0.0002
  weight_decay: 0.00001

  grad_clip: 1.0
  optimizer: adamw
  scheduler: constant
  
  # Checkpointing
  checkpoint_dir: "/oak/stanford/groups/swl1/lhy/checkpoints/generative_models/vqvae_cifar10"
  save_interval: 10  # Save every N epochs
  
  # Logging
  log_interval: 100  # Log every N steps
  sample_interval: 500  # Sample reconstructions every N steps
  num_samples: 8  # Number of images to reconstruct for logging

wandb:
  project: "generative-models"
  entity: null  # Set your wandb entity/username
  name: "vqvae_cifar10"
  tags: ["vqvae", "cifar10"]
  log_model: false

seed: 40